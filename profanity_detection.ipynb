{"metadata":{"orig_nbformat":4,"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Basic Profanity Detection with Machine Learning","metadata":{}},{"cell_type":"markdown","source":"This project involves using basic (shallow) Natural Language Processing features to try to detect whether a word is a profanity or not. Three datasets are used in this project, which contain profanities and words from the dictionary.","metadata":{}},{"cell_type":"markdown","source":"Imports","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport re\nfrom better_profanity import profanity\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import svm\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","metadata":{"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"markdown","source":"### Loading and Pre-processing Profanity + English Dictionary Datasets","metadata":{}},{"cell_type":"code","source":"#loads and creates a dataframe from a .txt list of profanities\nprofanity_data1 = []\nwith open('profanity_data.txt') as f:\n    lines = f.readlines()\n    for i in lines:\n        profanity_data1.append(i[:-1])\n    f.close()\nprofanity_data1 = pd.DataFrame(profanity_data1)\nprofanity_data1 = profanity_data1.rename(columns={0:\"Word\"})","metadata":{"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"#loads a creates a dataframe from a .csv of profanities\nprofanity_data2 = pd.read_csv(\"bad-words.csv\", header=None)\nprofanity_data2 = profanity_data2.rename(columns={0:\"Word\"})","metadata":{"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"#combines the two dataframes and creates a binary variable that indicates whether a word is a profanity or not (1 or 0)\nprofanity_df = pd.concat([profanity_data1, profanity_data2], join=\"inner\")\nprofanity_df = profanity_df.drop_duplicates()\nprofanity_df[\"Profanity_indicator\"] = 1","metadata":{"trusted":true},"execution_count":36,"outputs":[]},{"cell_type":"code","source":"#loads dictionary dataset\ndictionary_data = pd.read_csv(\"dictionary.csv\", header=None)\ndictionary_data = dictionary_data.rename(columns={0:\"Word\"})\ndictionary_data = dictionary_data.drop(columns=[1, 2])\n\n#removes any words with less than 3 characters, with empty spaces, and more than 10 characters\ndef remove_word(df):\n    \n    if len(df[\"Word\"]) <=2 or \" \" in df[\"Word\"]: #or len(df[\"Word\"]) >= 10:\n        return 1\n    else:\n        return 0\ndictionary_data[\"remove_word\"] = dictionary_data.apply(remove_word, axis=1)\ndictionary_data = dictionary_data[dictionary_data[\"remove_word\"] == 0]\ndictionary_data = dictionary_data.drop(columns=[\"remove_word\"])\n\n#gets a random sample of 4000 words to use later in training/testing\ndictionary_data = dictionary_data.sample(4000)\n\n#assigns profanity_indicator to 0\ndictionary_data[\"Profanity_indicator\"] = 0","metadata":{"trusted":true},"execution_count":156,"outputs":[]},{"cell_type":"code","source":"#combines the profanity and dictionary dataframes\nwords_dataset = pd.concat([profanity_df.copy(),profanity_df, dictionary_data])\n\n#creates addition variables to use as features\n\n#length of word\nwords_dataset[\"word_length\"] = words_dataset['Word'].str.len()\n\n#indicator of whether word is longer than avg\navg_word_len = words_dataset[\"word_length\"].mean()\ndef longer_than_avg(df):\n    if df[\"word_length\"] >= avg_word_len:\n        return 1\n    else:\n        return 0   \nwords_dataset[\"longer_than_avg\"] = words_dataset.apply(longer_than_avg, axis=1)\n\n#indicator of whether word has numerics\ndef num_numerics(df):\n    nums_in_str = re.findall(r'\\d', df[\"Word\"])\n    return len(nums_in_str)\nwords_dataset[\"num_in_string\"] = words_dataset.apply(num_numerics, axis=1)\n\n#uses the better_profanity package to create a binary variable of whether a word is censored or not\ndef censor(df):\n    try:\n        censored = profanity.censor(df[\"Word\"], '$')\n        if \"$\" in censored:\n            return 1\n        else:\n            return 0\n    except:\n        censored = profanity.censor(df, '$')\n        if \"$\" in censored:\n            return 1\n        else:\n            return 0\nwords_dataset[\"censored\"] = words_dataset.apply(censor, axis=1)\n\n\nwords_dataset","metadata":{"trusted":true},"execution_count":157,"outputs":[{"execution_count":157,"output_type":"execute_result","data":{"text/plain":"            Word  Profanity_indicator  word_length  longer_than_avg  \\\n0           4r5e                    1            4                0   \n1           5h1t                    1            4                0   \n2           5hit                    1            4                0   \n3            a55                    1            3                0   \n4           anal                    1            4                0   \n...          ...                  ...          ...              ...   \n13363       -ful                    0            4                0   \n16306   Gilbbery                    0            8                1   \n2211        Adit                    0            4                0   \n34153    Padrone                    0            7                0   \n45411  Scantness                    0            9                1   \n\n       num_in_string  censored  \n0                  2         1  \n1                  2         1  \n2                  1         1  \n3                  2         1  \n4                  0         1  \n...              ...       ...  \n13363              0         0  \n16306              0         0  \n2211               0         0  \n34153              0         0  \n45411              0         0  \n\n[7710 rows x 6 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Word</th>\n      <th>Profanity_indicator</th>\n      <th>word_length</th>\n      <th>longer_than_avg</th>\n      <th>num_in_string</th>\n      <th>censored</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4r5e</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>5h1t</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>5hit</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>a55</td>\n      <td>1</td>\n      <td>3</td>\n      <td>0</td>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>anal</td>\n      <td>1</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>13363</th>\n      <td>-ful</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>16306</th>\n      <td>Gilbbery</td>\n      <td>0</td>\n      <td>8</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2211</th>\n      <td>Adit</td>\n      <td>0</td>\n      <td>4</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>34153</th>\n      <td>Padrone</td>\n      <td>0</td>\n      <td>7</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>45411</th>\n      <td>Scantness</td>\n      <td>0</td>\n      <td>9</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>7710 rows Ã— 6 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Prepping Data for Training/Testing","metadata":{}},{"cell_type":"code","source":"from sklearn.model_selection import StratifiedShuffleSplit\n\nsss = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\nfor train_index, test_index in sss.split(words_dataset, words_dataset['Profanity_indicator']):\n    strat_train_set = words_dataset.iloc[train_index]\n    strat_test_set = words_dataset.iloc[test_index]\n    \nX_train = strat_train_set.drop('Profanity_indicator',axis=1).select_dtypes(np.number)\ny_train = strat_train_set['Profanity_indicator']\nX_test = strat_test_set.drop('Profanity_indicator', axis=1).select_dtypes(np.number)\ny_test = strat_test_set['Profanity_indicator']","metadata":{"trusted":true},"execution_count":158,"outputs":[]},{"cell_type":"markdown","source":"### Picking a Classification Model","metadata":{}},{"cell_type":"code","source":"models = [\n    RandomForestClassifier(n_estimators=50,random_state=42, criterion='entropy',max_depth=None, min_samples_split=2),\n    svm.SVC(gamma=\"scale\",kernel=\"rbf\"),\n    GaussianNB(),\n    DecisionTreeClassifier(),\n    LogisticRegression()\n    \n    \n]\n\nmodel_names = ['rf','svm','dt','nb', 'lr']","metadata":{"trusted":true},"execution_count":159,"outputs":[]},{"cell_type":"code","source":"accuracy = []\nfor model in models:\n    \n        model.fit(X_train,y_train)\n\n        y_pred = model.predict(X_test)\n\n        # evaluate predictions\n        accuracy.append(model.score(X_test, y_test))\n        \nfor i in range(5):\n    print(\"Accuracy for \" + model_names[i] + \": %.2f%%\" % (accuracy[i] * 100.0))","metadata":{"trusted":true},"execution_count":160,"outputs":[{"name":"stdout","text":"Accuracy for rf: 68.55%\nAccuracy for svm: 68.55%\nAccuracy for dt: 68.42%\nAccuracy for nb: 68.55%\nAccuracy for lr: 68.42%\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Random Forest Classifier on Profanity","metadata":{}},{"cell_type":"code","source":"#Create a Gaussian Classifier\nclf=RandomForestClassifier(n_estimators=100)\n\n#Train the model\nclf.fit(X_train,y_train)\n\ny_pred=clf.predict(X_test)","metadata":{"trusted":true},"execution_count":161,"outputs":[]},{"cell_type":"code","source":"#Import scikit-learn metrics module for accuracy calculation\nfrom sklearn import metrics\n# Model Accuracy\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))","metadata":{"trusted":true},"execution_count":162,"outputs":[{"name":"stdout","text":"Accuracy: 0.685473411154345\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Profanity Checker","metadata":{}},{"cell_type":"code","source":"def profanity_checker(word):\n    #word = input(\"Please enter a word: \")\n\n    def user_longer_avg(word):\n        if len(word) >= avg_word_len:\n            return 1\n        else:\n            return 0\n    \n    def user_string_num(word):\n        bool_numeric = re.search(r'\\d', word)\n        if bool_numeric != None:\n            return 1\n        else:\n            return 0    \n    \n    word_features = [len(word), user_longer_avg(word), user_string_num(word), censor(word)]\n    \n    prediction = clf.predict([word_features])[0]\n    if prediction == 1:\n        return word + \" is a profanity\"\n    else:\n        return word + \" is not a profanity\"","metadata":{"trusted":true},"execution_count":163,"outputs":[]},{"cell_type":"code","source":"profanity_checker(\"truck\")","metadata":{"trusted":true},"execution_count":172,"outputs":[{"execution_count":172,"output_type":"execute_result","data":{"text/plain":"'truck is not a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"profanity_checker(\"fuck\")","metadata":{"trusted":true},"execution_count":170,"outputs":[{"execution_count":170,"output_type":"execute_result","data":{"text/plain":"'fuck is a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"profanity_checker(\"frick\")","metadata":{"trusted":true},"execution_count":173,"outputs":[{"execution_count":173,"output_type":"execute_result","data":{"text/plain":"'frick is not a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"profanity_checker(\"fu1ck\")","metadata":{"trusted":true},"execution_count":175,"outputs":[{"execution_count":175,"output_type":"execute_result","data":{"text/plain":"'fu1ck is a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"profanity_checker(\"duck\")","metadata":{"trusted":true},"execution_count":176,"outputs":[{"execution_count":176,"output_type":"execute_result","data":{"text/plain":"'duck is not a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"profanity_checker(\"pluck\")","metadata":{"trusted":true},"execution_count":177,"outputs":[{"execution_count":177,"output_type":"execute_result","data":{"text/plain":"'pluck is not a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"profanity_checker(\"luck\")","metadata":{"trusted":true},"execution_count":178,"outputs":[{"execution_count":178,"output_type":"execute_result","data":{"text/plain":"'luck is not a profanity'"},"metadata":{}}]},{"cell_type":"code","source":"#re testing model with previous profanity dataset\ntest1 = profanity_data1[\"Word\"].to_list()\ncorrect1 = 0\nfor i in test1:\n    #print(i)\n    prediction1 = profanity_checker(i)\n    #print(prediction)\n    if \"not\" not in prediction1:\n        correct1 +=1\n        \nprint(\"Predicted \" + str(correct1) + \" correctly out of \" + str(len(test1)) + \" words.\")","metadata":{"trusted":true},"execution_count":174,"outputs":[{"name":"stdout","text":"Predicted 411 correctly out of 451 words.\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}